var tree =
[
  {
    "text": "Deep Learning - Journal Club",
    "item-id": "c25,iNone",
    "nodes": [
      {
        "text": "2020/11/13 - Benjamin Remy",
        "item-id": "c30,i1641",
        "nodes": [
          {
            "text": "Your Classifier is Secretely an Energy Based Model and You Should Treat it Like One",
            "item-id": "i1641",
            "nodes": [
              {
                "text": "Grathwohl et al2020Your Classifier is Secretely an Energy Based Model and You Should Treat it Like.pdf",
                "item-id": "i1642",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Grathwohl et al2020Your Classifier is Secretely an Energy Based Model and You Should Treat it Like.pdf",
                "item_type": "attachment",
                "item_note": "<div class=\"zotero-note znv1\"><p xmlns=\"http://www.w3.org/1999/xhtml\" id=\"title\"><strong>Contents</strong></p><ul xmlns=\"http://www.w3.org/1999/xhtml\" style=\"list-style-type: none; padding-left:0px\" id=\"toc\"><li><a href=\"zotero://open-pdf/0_IBPUPZ8X/1\">Introduction</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/2\">Energy Based Models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/2\">What your classifier is hiding</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/3\">Optimization</a></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/3\">Applications</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/4\">Hybrid modeling</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/4\">Calibration</a></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/5\">Out-Of-Distribution Detection</a><ul style=\"list-style-type: none; padding-left:24px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/5\">Input Density</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/5\">Predictive Distribution</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/6\">A new score: Approximate Mass</a></li></ul></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/6\">Robustness</a><ul style=\"list-style-type: none; padding-left:24px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/7\">Improved Robustness Through EBM Training</a></li></ul></li></ul></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/8\">Limitations</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/8\">Related Work</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/9\">Conclusion and Further Work</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/9\">Acknowledgements</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/13\">Training Details</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/13\">Sample Quality Evalution</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/15\">Further Hybrid Model Samples</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/16\">Qualitative Analysis of Samples</a></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/18\">Calibration</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/18\">Expected Calibration Error</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/18\">Further results</a></li></ul></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/19\">Ouf-Of-Distribution Detection</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/19\">Experimental details</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/19\">Further results</a></li></ul></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/19\">Attack Details and Further Robustness Results</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/20\">Expectation Over Transformations</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/21\">Transfer Attacks</a></li></ul></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/21\">A Discussion on Samplers</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/21\">Improper SGLD</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/22\">Persistent or Short-run Chains?</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IBPUPZ8X/23\">Dealing with Instability</a></li></ul></li></ul></div>",
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Grathwohl et al2020Your Classifier is Secretely an Energy Based Model and You Should Treat it Like.pdf"
                  ]
                ],
                "resource": "storage/i1642.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Your Classifier is Secretely an Energy Based Model and You Should Treat it Like One",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "We propose to reinterpret a standard discriminative classi\ufb01er of p(y|x) as an energy based model for the joint distribution p(x, y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may be used and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, and out-of-distribution detection while also enabling our models to generate samples rivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and present an approach which adds little overhead compared to standard classi\ufb01cation training. Our approach is able to achieve performance rivaling the state-of-the-art in both generative and discriminative learning within one hybrid model."
              ],
              [
                "Creators",
                "Will Grathwohl, Kuan-Chieh Wang, Jorn-Henrik Jacobsen"
              ],
              [
                "Date",
                "2020-00-00 2020"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "Zotero"
              ],
              [
                "Pages",
                "23"
              ],
              [
                "Title",
                "Your Classifier is Secretely an Energy Based Model and You Should Treat it Like One"
              ]
            ],
            "resource": "storage/i1642.pdf",
            "selectable": false
          }
        ],
        "item_title": "2020/11/13 - Benjamin Remy",
        "item_type": null,
        "item_note": null,
        "node_type": "collection",
        "selectable": false
      },
      {
        "text": "2020/10/30 - Chlo\u00e9",
        "item-id": "c28,i1634",
        "nodes": [
          {
            "text": "BrainNetCNN",
            "item-id": "i624",
            "nodes": [
              {
                "text": "Kawahara et al2017BrainNetCNN.pdf",
                "item-id": "i847",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Kawahara et al2017BrainNetCNN.pdf",
                "item_type": "attachment",
                "item_note": null,
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Kawahara et al2017BrainNetCNN.pdf"
                  ]
                ],
                "resource": "storage/i847.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "BrainNetCNN",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "We propose BrainNetCNN, a convolutional neural network (CNN) framework to predict clinical neurodevelopmental outcomes from brain networks. In contrast to the spatially local convolutions done in traditional image-based CNNs, our BrainNetCNN is composed of novel edge-to-edge, edge-to-node and node-to-graph convolutional \ufb01lters that leverage the topological locality of structural brain networks. We apply the BrainNetCNN framework to predict cognitive and motor developmental outcome scores from structural brain networks of infants born preterm. Di\ufb00usion tensor images (DTI) of preterm infants, acquired between 27 and 46 weeks gestational age, were used to construct a dataset of structural brain connectivity networks. We \ufb01rst demonstrate the predictive capabilities of BrainNetCNN on synthetic phantom networks with simulated injury patterns and added noise. BrainNetCNN outperforms a fully connected neural-network with the same number of model parameters on both phantoms with focal and di\ufb00use injury patterns. We then apply our method to the task of joint prediction of Bayley-III cognitive and motor scores, assessed at 18 months of age, adjusted for prematurity. We show that our BrainNetCNN framework outperforms a variety of other methods on the same data. Furthermore, BrainNetCNN is able to identify an infant\u2019s post menstrual age to within about 2 weeks. Finally, we explore the high-level features learned by BrainNetCNN by visualizing the importance of each connection in the brain with respect to predicting the outcome scores. These \ufb01ndings are then discussed in the context of the anatomy and function of the developing preterm infant brain."
              ],
              [
                "Access Date",
                "2020-01-21 17:39:25"
              ],
              [
                "Creators",
                "Jeremy Kawahara, Colin J. Brown, Steven P. Miller, Brian G. Booth, Vann Chau, Ruth E. Grunau, Jill G. Zwicker, Ghassan Hamarneh"
              ],
              [
                "DOI",
                "10.1016/j.neuroimage.2016.09.046"
              ],
              [
                "Date",
                "2017-02-00 02/2017"
              ],
              [
                "ISSN",
                "10538119"
              ],
              [
                "Journal Abbreviation",
                "NeuroImage"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "DOI.org (Crossref)"
              ],
              [
                "Pages",
                "1038-1049"
              ],
              [
                "Publication Title",
                "NeuroImage"
              ],
              [
                "Short Title",
                "BrainNetCNN"
              ],
              [
                "Title",
                "BrainNetCNN: Convolutional neural networks for brain networks; towards predicting neurodevelopment"
              ],
              [
                "URL",
                "https://linkinghub.elsevier.com/retrieve/pii/S1053811916305237"
              ],
              [
                "Volume",
                "146"
              ]
            ],
            "resource": "storage/i847.pdf",
            "selectable": false
          },
          {
            "text": "Deep Clustering for Unsupervised Learning of Visual Features",
            "item-id": "i1631",
            "nodes": [
              {
                "text": "Comment: Accepted at ECCV 2018",
                "item-id": "n1632",
                "icon": "glyphicon glyphicon-text-background",
                "item_title": "Comment: Accepted at ECCV 2018",
                "item_type": "note",
                "item_note": "<div class=\"zotero-note znv1\">Comment: Accepted at ECCV 2018</div>",
                "node_type": "note"
              },
              {
                "text": "Caron et al2019Deep Clustering for Unsupervised Learning of Visual Features.pdf",
                "item-id": "i1637",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Caron et al2019Deep Clustering for Unsupervised Learning of Visual Features.pdf",
                "item_type": "attachment",
                "item_note": "<div class=\"zotero-note znv1\"><p xmlns=\"http://www.w3.org/1999/xhtml\" id=\"title\"><strong>Contents</strong></p><ul xmlns=\"http://www.w3.org/1999/xhtml\" style=\"list-style-type: none; padding-left:0px\" id=\"toc\"><li><a href=\"zotero://open-pdf/0_PNUYY5AU/1\">Deep Clustering for Unsupervised Learning  of Visual Features</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_PNUYY5AU/20\">Appendix</a></li></ul></div>",
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Caron et al2019Deep Clustering for Unsupervised Learning of Visual Features.pdf"
                  ]
                ],
                "resource": "storage/i1637.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Deep Clustering for Unsupervised Learning of Visual Features",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, kmeans, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a signi\ufb01cant margin on all the standard benchmarks."
              ],
              [
                "Access Date",
                "2020-11-24 14:21:15"
              ],
              [
                "Creators",
                "Mathilde Caron, Piotr Bojanowski, Armand Joulin, Matthijs Douze"
              ],
              [
                "Date",
                "2019-03-18 2019-03-18"
              ],
              [
                "Extra",
                "arXiv: 1807.05520"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "arXiv.org"
              ],
              [
                "Publication Title",
                "arXiv:1807.05520 [cs]"
              ],
              [
                "Title",
                "Deep Clustering for Unsupervised Learning of Visual Features"
              ],
              [
                "URL",
                "http://arxiv.org/abs/1807.05520"
              ]
            ],
            "resource": "storage/i1637.pdf",
            "selectable": false
          },
          {
            "text": "Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets",
            "item-id": "i1633",
            "nodes": [
              {
                "text": "Schulz et al2020Different scaling of linear models and deep learning in UKBiobank brain images.pdf",
                "item-id": "i1636",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Schulz et al2020Different scaling of linear models and deep learning in UKBiobank brain images.pdf",
                "item_type": "attachment",
                "item_note": "<div class=\"zotero-note znv1\"><p xmlns=\"http://www.w3.org/1999/xhtml\" id=\"title\"><strong>Contents</strong></p><ul xmlns=\"http://www.w3.org/1999/xhtml\" style=\"list-style-type: none; padding-left:0px\" id=\"toc\"><li><a href=\"zotero://open-pdf/0_IYMSGHQX/2\">Results</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/2\">Rationale and summary of workflow</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/3\">Model performance on machine learning reference datasets</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/5\">Performances on brain images scales similar to linear models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/5\">Performance of DNN models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/6\">Performance of 3D convolutional DNN models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/6\">Impact of noise on nonlinear classification</a></li></ul></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/7\">Discussion</a></li><li style=\"padding-top:8px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/12\">Methods</a><ul style=\"list-style-type: none; padding-left:12px\"><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/12\">Three reference datasets</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/13\">Preprocessing procedures</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/13\">Linear models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/13\">Nonlinear models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/13\">Hierarchically nonlinear models</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/13\">Model selection and model evaluation</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/14\">Sample complexity analysis</a></li></ul></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/14\">Reporting summary</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/14\">Data availability</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/14\">Code availability</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/14\">References</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/15\">Acknowledgements</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/15\">Author contributions</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/15\">Competing interests</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_IYMSGHQX/15\">Additional information</a></li></ul></div>",
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Schulz et al2020Different scaling of linear models and deep learning in UKBiobank brain images.pdf"
                  ]
                ],
                "resource": "storage/i1636.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Access Date",
                "2020-11-24 14:21:24"
              ],
              [
                "Creators",
                "Marc-Andre Schulz, B. T. Thomas Yeo, Joshua T. Vogelstein, Janaina Mourao-Miranada, Jakob N. Kather, Konrad Kording, Blake Richards, Danilo Bzdok"
              ],
              [
                "DOI",
                "10.1038/s41467-020-18037-z"
              ],
              [
                "Date",
                "2020-12-00 12/2020"
              ],
              [
                "ISSN",
                "2041-1723"
              ],
              [
                "Issue",
                "1"
              ],
              [
                "Journal Abbreviation",
                "Nat Commun"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "DOI.org (Crossref)"
              ],
              [
                "Pages",
                "4238"
              ],
              [
                "Publication Title",
                "Nature Communications"
              ],
              [
                "Title",
                "Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets"
              ],
              [
                "URL",
                "http://www.nature.com/articles/s41467-020-18037-z"
              ],
              [
                "Volume",
                "11"
              ]
            ],
            "resource": "storage/i1636.pdf",
            "selectable": false
          },
          {
            "text": "Predicting Cortical Signatures of Consciousness using Dynamic Functional Connectivity Graph-Convolutional Neural Networks",
            "item-id": "i1634",
            "nodes": [
              {
                "text": "Grigis et al2020Predicting Cortical Signatures of Consciousness using Dynamic Functional.pdf",
                "item-id": "i1635",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Grigis et al2020Predicting Cortical Signatures of Consciousness using Dynamic Functional.pdf",
                "item_type": "attachment",
                "item_note": null,
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Grigis et al2020Predicting Cortical Signatures of Consciousness using Dynamic Functional.pdf"
                  ]
                ],
                "resource": "storage/i1635.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-font",
            "item_title": "Predicting Cortical Signatures of Consciousness using Dynamic Functional Connectivity Graph-Convolutional Neural Networks",
            "item_type": "report",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "Decoding the levels of consciousness from cortical activity recording is a major challenge in neuroscience. Using clustering algorithms, we previously demonstrated that resting-state functional MRI (rsfMRI) data can be split into several clusters also called \u201cbrain states\u201d corresponding to \u201cfunctional configurations\u201d of the brain. Here, we propose to use a supervised machine learning method based on artificial neural networks to predict functional brain states across levels of consciousness from rsfMRI. Because it is key to consider the topology of brain regions used to build the dynamical functional connectivity matrices describing the brain state at a given time, we applied BrainNetCNN, a graphconvolutional neural network (CNN), to predict the brain states in awake and anesthetized non-human primate rsfMRI data. BrainNetCNN achieved a high prediction accuracy that lies in [0.674, 0.765] depending on the experimental settings. We propose to derive the set of connections found to be important for predicting a brain state, reflecting the level of consciousness. The results demonstrate that deep learning methods can be used not only to predict brain states but also to provide additional insight on cortical signatures of consciousness with potential clinical consequences for the monitoring of anesthesia and the diagnosis of disorders of consciousness."
              ],
              [
                "Access Date",
                "2020-11-24 14:21:30"
              ],
              [
                "Creators",
                "A. Grigis, J. Tasserie, V. Frouin, B. Jarraya, L. Uhrig"
              ],
              [
                "Date",
                "2020-05-12 2020-05-12"
              ],
              [
                "Extra",
                "DOI: 10.1101/2020.05.11.078535"
              ],
              [
                "Institution",
                "Neuroscience"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "DOI.org (Crossref)"
              ],
              [
                "Report Type",
                "preprint"
              ],
              [
                "Title",
                "Predicting Cortical Signatures of Consciousness using Dynamic Functional Connectivity Graph-Convolutional Neural Networks"
              ],
              [
                "URL",
                "http://biorxiv.org/lookup/doi/10.1101/2020.05.11.078535"
              ]
            ],
            "resource": "storage/i1635.pdf",
            "selectable": false
          }
        ],
        "item_title": "2020/10/30 - Chlo\u00e9",
        "item_type": null,
        "item_note": null,
        "node_type": "collection",
        "selectable": false
      },
      {
        "text": "2020/11/06 - Cl\u00e9ment Poiret",
        "item-id": "c29,i1547",
        "nodes": [
          {
            "text": "Equivariant neural networks and equivarification",
            "item-id": "i1547",
            "nodes": [
              {
                "text": "Comment: More explanations added",
                "item-id": "n1548",
                "icon": "glyphicon glyphicon-text-background",
                "item_title": "Comment: More explanations added",
                "item_type": "note",
                "item_note": "<div class=\"zotero-note znv1\">Comment: More explanations added</div>",
                "node_type": "note"
              },
              {
                "text": "Bao_Song2020Equivariant neural networks and equivarification.pdf",
                "item-id": "i1567",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Bao_Song2020Equivariant neural networks and equivarification.pdf",
                "item_type": "attachment",
                "item_note": "<div class=\"zotero-note znv1\"><p xmlns=\"http://www.w3.org/1999/xhtml\" id=\"title\"><strong>Contents</strong></p><ul xmlns=\"http://www.w3.org/1999/xhtml\" style=\"list-style-type: none; padding-left:0px\" id=\"toc\"><li><a href=\"zotero://open-pdf/0_3BH34L5U/1\">1. Introduction</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/3\">2. Preliminaries</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/5\">3. Equivarification</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/6\">4. Application to neural networks</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/9\">5. Experiments</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/10\">6. Conclusion</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/11\">Appendix A. More About Equivarification</a></li><li style=\"padding-top:4px\"><a href=\"zotero://open-pdf/0_3BH34L5U/12\">References</a></li></ul></div>",
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Bao_Song2020Equivariant neural networks and equivarification.pdf"
                  ]
                ],
                "resource": "storage/i1567.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Equivariant neural networks and equivarification",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "Equivariant neural networks are special types of neural networks that preserve some symmetries on the data set. In this paper, we provide a method to modify a neural network to an equivariant one, which we call equivari\ufb01cation. Existing works explore several special cases of equivari\ufb01cation which need to design equivariant layers according to detailed functions of each layer and cannot be generalized to arbitrary networks or functions. In contrast, by leveraging a group action theory, our proposed equivari\ufb01cation method enables to design an equivariant neural network uniformly across layers of feedforward neural networks, such as multi-layer perceptrons, convolutional neural networks. A key difference from existing works is that our equivari\ufb01cation method can be applied without knowledge of the detailed functions of a layer in a neural network, and hence, can be generalized to any feedforward neural networks. As an illustration, we build an equivariant neural network for image classi\ufb01cation by equivarifying a convolutional neural network. Results show that our proposed method signi\ufb01cantly reduces the design and training complexity, yet preserving the learning performance in terms of accuracy."
              ],
              [
                "Access Date",
                "2020-10-22 09:15:17"
              ],
              [
                "Creators",
                "Erkao Bao, Linqi Song"
              ],
              [
                "Date",
                "2020-03-22 2020-03-22"
              ],
              [
                "Extra",
                "arXiv: 1906.07172"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "arXiv.org"
              ],
              [
                "Publication Title",
                "arXiv:1906.07172 [cs, stat]"
              ],
              [
                "Title",
                "Equivariant neural networks and equivarification"
              ],
              [
                "URL",
                "http://arxiv.org/abs/1906.07172"
              ]
            ],
            "resource": "storage/i1567.pdf",
            "selectable": false
          },
          {
            "text": "Rotation equivariant and invariant neural networks for microscopy image analysis",
            "item-id": "i1531",
            "nodes": [
              {
                "text": "Chidester et al2019Rotation equivariant and invariant neural networks for microscopy image analysis.pdf",
                "item-id": "i1639",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Chidester et al2019Rotation equivariant and invariant neural networks for microscopy image analysis.pdf",
                "item_type": "attachment",
                "item_note": null,
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Chidester et al2019Rotation equivariant and invariant neural networks for microscopy image analysis.pdf"
                  ]
                ],
                "resource": "storage/i1639.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Rotation equivariant and invariant neural networks for microscopy image analysis",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "Abstract\n            \n              Motivation\n              Neural networks have been widely used to analyze high-throughput microscopy images. However, the performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Highly relevant to the goal of automated cell phenotyping from microscopy image data is rotation invariance. Here we consider the application of two schemes for encoding rotation equivariance and invariance in a convolutional neural network, namely, the group-equivariant CNN (G-CNN), and a new architecture with simple, efficient conic convolution, for classifying microscopy images. We additionally integrate the 2D-discrete-Fourier transform (2D-DFT) as an effective means for encoding global rotational invariance. We call our new method the Conic Convolution and DFT Network (CFNet).\n            \n            \n              Results\n              We evaluated the efficacy of CFNet and G-CNN as compared to a standard CNN for several different image classification tasks, including simulated and real microscopy images of subcellular protein localization, and demonstrated improved performance. We believe CFNet has the potential to improve many high-throughput microscopy image analysis applications.\n            \n            \n              Availability and implementation\n              Source code of CFNet is available at: https://github.com/bchidest/CFNet.\n            \n            \n              Supplementary information\n              Supplementary data are available at Bioinformatics online."
              ],
              [
                "Access Date",
                "2020-10-05 08:34:57"
              ],
              [
                "Creators",
                "Benjamin Chidester, Tianming Zhou, Minh N Do, Jian Ma"
              ],
              [
                "DOI",
                "10.1093/bioinformatics/btz353"
              ],
              [
                "Date",
                "2019-07-15 2019-07-15"
              ],
              [
                "ISSN",
                "1367-4803, 1460-2059"
              ],
              [
                "Issue",
                "14"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "DOI.org (Crossref)"
              ],
              [
                "Pages",
                "i530-i537"
              ],
              [
                "Publication Title",
                "Bioinformatics"
              ],
              [
                "Title",
                "Rotation equivariant and invariant neural networks for microscopy image analysis"
              ],
              [
                "URL",
                "https://academic.oup.com/bioinformatics/article/35/14/i530/5529148"
              ],
              [
                "Volume",
                "35"
              ]
            ],
            "resource": "storage/i1639.pdf",
            "selectable": false
          }
        ],
        "item_title": "2020/11/06 - Cl\u00e9ment Poiret",
        "item_type": null,
        "item_note": null,
        "node_type": "collection",
        "selectable": false
      },
      {
        "text": "2020/11/20 - Zaccharie Ramzi",
        "item-id": "c31,i1644",
        "nodes": [
          {
            "text": "Deep Image Prior",
            "item-id": "i1644",
            "nodes": [
              {
                "text": "Ulyanov et al2020Deep Image Prior.pdf",
                "item-id": "i1645",
                "icon": "glyphicon glyphicon-paperclip",
                "item_title": "Ulyanov et al2020Deep Image Prior.pdf",
                "item_type": "attachment",
                "item_note": null,
                "node_type": "item",
                "metadata": [
                  [
                    "Title",
                    "Ulyanov et al2020Deep Image Prior.pdf"
                  ]
                ],
                "resource": "storage/i1645.pdf"
              }
            ],
            "icon": "glyphicon glyphicon-file",
            "item_title": "Deep Image Prior",
            "item_type": "journalArticle",
            "item_note": null,
            "node_type": "item",
            "metadata": [
              [
                "Abstract Note",
                "Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is su\ufb03cient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, superresolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on \ufb02ash-no \ufb02ash input pairs."
              ],
              [
                "Access Date",
                "2020-11-24 14:27:09"
              ],
              [
                "Creators",
                "Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky"
              ],
              [
                "DOI",
                "10.1007/s11263-020-01303-4"
              ],
              [
                "Date",
                "2020-07-00 7/2020"
              ],
              [
                "Extra",
                "arXiv: 1711.10925"
              ],
              [
                "ISSN",
                "0920-5691, 1573-1405"
              ],
              [
                "Issue",
                "7"
              ],
              [
                "Journal Abbreviation",
                "Int J Comput Vis"
              ],
              [
                "Language",
                "en"
              ],
              [
                "Library Catalog",
                "arXiv.org"
              ],
              [
                "Pages",
                "1867-1888"
              ],
              [
                "Publication Title",
                "International Journal of Computer Vision"
              ],
              [
                "Title",
                "Deep Image Prior"
              ],
              [
                "URL",
                "http://arxiv.org/abs/1711.10925"
              ],
              [
                "Volume",
                "128"
              ]
            ],
            "resource": "storage/i1645.pdf",
            "selectable": false
          }
        ],
        "item_title": "2020/11/20 - Zaccharie Ramzi",
        "item_type": null,
        "item_note": null,
        "node_type": "collection",
        "selectable": false
      }
    ],
    "item_title": "Deep Learning - Journal Club",
    "item_type": null,
    "item_note": null,
    "node_type": "collection",
    "selectable": false
  }
]